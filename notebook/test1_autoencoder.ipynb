{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_2:0\", shape=(?, 784), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "print(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "10000\n",
      "[[[0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]\n",
      "\n",
      " ..., \n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  ..., \n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]\n",
      "  [0 0 0 ..., 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(len(x_test))\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#We will normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784.\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.3795 - val_loss: 0.2729\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2661 - val_loss: 0.2558\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2456 - val_loss: 0.2331\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2252 - val_loss: 0.2150\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2099 - val_loss: 0.2024\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1991 - val_loss: 0.1929\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1904 - val_loss: 0.1848\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1827 - val_loss: 0.1777\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1761 - val_loss: 0.1716\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1704 - val_loss: 0.1664\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1656 - val_loss: 0.1618\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1613 - val_loss: 0.1577\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1574 - val_loss: 0.1539\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1538 - val_loss: 0.1504\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1505 - val_loss: 0.1474\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1475 - val_loss: 0.1444\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1447 - val_loss: 0.1419\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1421 - val_loss: 0.1392\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1398 - val_loss: 0.1369\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1375 - val_loss: 0.1348\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1354 - val_loss: 0.1327\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1334 - val_loss: 0.1307\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1315 - val_loss: 0.1289\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1297 - val_loss: 0.1271\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1279 - val_loss: 0.1254\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1262 - val_loss: 0.1237\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1246 - val_loss: 0.1222\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1231 - val_loss: 0.1207\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1216 - val_loss: 0.1192\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1202 - val_loss: 0.1178\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1189 - val_loss: 0.1165\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1176 - val_loss: 0.1152\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1164 - val_loss: 0.1141\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1152 - val_loss: 0.1130\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1142 - val_loss: 0.1119\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1131 - val_loss: 0.1110\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1122 - val_loss: 0.1100\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1113 - val_loss: 0.1091\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1104 - val_loss: 0.1083\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1096 - val_loss: 0.1075\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1089 - val_loss: 0.1068\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1082 - val_loss: 0.1062\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1076 - val_loss: 0.1056\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1070 - val_loss: 0.1050\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1064 - val_loss: 0.1044\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1059 - val_loss: 0.1039\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1054 - val_loss: 0.1035\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1050 - val_loss: 0.1031\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1045 - val_loss: 0.1027\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1041 - val_loss: 0.1023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcce5792d30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfzdMht51MWE1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccc8492828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2962 - val_loss: 0.2959\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2954 - val_loss: 0.2951\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2947 - val_loss: 0.2944\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2940 - val_loss: 0.2937\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2933 - val_loss: 0.2930\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2926 - val_loss: 0.2924\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2920 - val_loss: 0.2917\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2914 - val_loss: 0.2911\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.290 - 2s - loss: 0.2908 - val_loss: 0.2906\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2902 - val_loss: 0.2900\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2897 - val_loss: 0.2895\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2892 - val_loss: 0.2889\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2886 - val_loss: 0.2884\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2882 - val_loss: 0.2880\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.287 - 2s - loss: 0.2877 - val_loss: 0.2875\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2872 - val_loss: 0.2870\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2868 - val_loss: 0.2866\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2864 - val_loss: 0.2862\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2859 - val_loss: 0.2858\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2855 - val_loss: 0.2854\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2851 - val_loss: 0.2850\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2848 - val_loss: 0.2846\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2844 - val_loss: 0.2842\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2840 - val_loss: 0.2839\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2837 - val_loss: 0.2835\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2834 - val_loss: 0.2832\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2830 - val_loss: 0.2829\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2827 - val_loss: 0.2826\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2824 - val_loss: 0.2823\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2821 - val_loss: 0.2820\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2818 - val_loss: 0.2817\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2815 - val_loss: 0.2814\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2813 - val_loss: 0.2811\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2810 - val_loss: 0.2809\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2807 - val_loss: 0.2806\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2805 - val_loss: 0.2803\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2802 - val_loss: 0.2801\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2800 - val_loss: 0.2798\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2798 - val_loss: 0.2796\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2795 - val_loss: 0.2794\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2793 - val_loss: 0.2792\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2791 - val_loss: 0.2789\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2789 - val_loss: 0.2787\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2787 - val_loss: 0.2785\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2785 - val_loss: 0.2783\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2783 - val_loss: 0.2781\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2781 - val_loss: 0.2779\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2779 - val_loss: 0.2777\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2777 - val_loss: 0.2776\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2775 - val_loss: 0.2774\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2773 - val_loss: 0.2772\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2772 - val_loss: 0.2770\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2770 - val_loss: 0.2768\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2768 - val_loss: 0.2767\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2767 - val_loss: 0.2765\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2765 - val_loss: 0.2764\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2763 - val_loss: 0.2762\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2762 - val_loss: 0.2761\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2760 - val_loss: 0.2759\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2759 - val_loss: 0.2758\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2758 - val_loss: 0.2756\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2756 - val_loss: 0.2755\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2755 - val_loss: 0.2753\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2753 - val_loss: 0.2752\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2752 - val_loss: 0.2751\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2751 - val_loss: 0.2749\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2750 - val_loss: 0.2748\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2748 - val_loss: 0.2747\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2747 - val_loss: 0.2746\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2746 - val_loss: 0.2744\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2745 - val_loss: 0.2743\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2743 - val_loss: 0.2742\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2742 - val_loss: 0.2741\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2741 - val_loss: 0.2740\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2740 - val_loss: 0.2739\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2739 - val_loss: 0.2738\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2738 - val_loss: 0.2736\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2737 - val_loss: 0.2735\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2736 - val_loss: 0.2734\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2735 - val_loss: 0.2733\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2734 - val_loss: 0.2732\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2733 - val_loss: 0.2731\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2732 - val_loss: 0.2730\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2731 - val_loss: 0.2729\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2730 - val_loss: 0.2729\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2729 - val_loss: 0.2728\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2728 - val_loss: 0.2727\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2727 - val_loss: 0.2726\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2727 - val_loss: 0.2725\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2726 - val_loss: 0.2724\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2725 - val_loss: 0.2723\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2724 - val_loss: 0.2722\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2723 - val_loss: 0.2722\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2722 - val_loss: 0.2721\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2722 - val_loss: 0.2720\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2721 - val_loss: 0.2719\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2720 - val_loss: 0.2718\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s - loss: 0.2719 - val_loss: 0.2718\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2719 - val_loss: 0.2717\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s - loss: 0.2718 - val_loss: 0.2716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fccab9526d8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10844054653596964144\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 209649664\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 5814308990410084344\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 745, pci bus id: 0000:01:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.client.session.Session object at 0x7fe5664b9588>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prapan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "device_name = sys.argv[0]\n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
